


 





mydefDefinition


./images/













 



 























   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)



rCRF: Recursive Belief Estimation over CRFs in RGB-D Activity Videos


Author Names Omitted for Anonymous Review. Paper-ID [add your ID here]



For robots, modeling the evolution of the activities over time and modeling the rich relationships in the scene are equally important for succesfull anticipation of future human activities. Moreover, robots not only need not to have an access to the most likely future, they also need all plausible futures with their respective probabilities.

While Bayesian filtering over a generative model is good for integrating the measurements over time for computing future state beliefs, they do not directly apply when the state and the measurements have a rich structure. In such a case, a Condition Random Field (CRF) can model the structure well. However, its discriminative nature prevents the computation of the beliefs.




We present a new recursive approach that we call Recursive CRF (rCRF). It uses the rich modeling power of  CRF in  recursive Bayesian filtering setting in order to compute an accurate belief. We then describe a computationally-tractable inference algorithm using structured diversity. In our experiments, we show that incorporating a belief computed via our approach significantly outperforms the state-of-the-art methods in the tasks of human activity detection and anticipation.








Introduction
The robots working with humans need not only to detect human actions but also need to anticipate them in order to perform reactive responses. Anticipation ability is especially important for the case of assitive robotic through avoiding conflict and performing the part of the tas human will perform. For example, Koppula et al. used anticipation in assitive robotic setting and sucesfully opened doors and served drinks by reacting to possible future human actions.






 

Anticipation of the possible human activities, require us to model the relationships between several objects and the human(s) in the scene as well as the temporal evolution of the scene. A standard approach is using a Conditional Random Field (CRF) to represent the relations between the objects, human(s) and activities.  In general, it is possible to obtain the maximum a posteriori (MAP) solution over a CRF efficiently. However, making a decision in such applications by solely relying on the MAP solution is sub-optimal since all possible solutions and their respective probabilities are required for an optimal decision (e.g. minimum Bayes risk). Hence, finding an appropriate reactive response requires not only the most likely state but also a belief over the current and the future states. A recent work, empirically computes modes of the CRF likelihood by relying on the diverse samples. While this work does not apply directly to estimating beliefs in a Bayesian filtering setting,  We use the diverse sampling ideas for efficient inference in our model
(see Section  for more details).


Figure showing our state and measurements at each time represented by a CRF.
Our new model, rCRF, computes the full belief over human activity and object affordances () by using RGB-D Video ().

Our model also allows anticipation of the belief in the future frames.





Bayesian filtering methods can accurately estimate a belief over variables of interest from sequential data. However, they are not applicable to CRF based scene models for two reasons. Firstly, it is not tractable to enumerate the labels over a CRF model since the output space of a CRF has a dimension exponential in the number of objects, labels, and the temporal length.(Typically with 10 objects, 10 minutes length observation (with 1 second long temporal segments), 10 activity labels and 10 object affordance labels, dimension of the space is )
 Secondly, there is a modeling mismatch between CRFs and Bayesian filtering formulation. CRF is based on a discriminative setting where it models the conditional probability of the variables of interest given an observation. On the other hand, Bayesian filtering is a generative setting that requires the conditional probability of the observation given the variables of interest.

In this paper, we present a recursive model - Recursive CRF (rCRF) - with an efficient belief estimation method in order to use CRF-based scene model in Bayesian filtering setting. rCRF models the temporal evolution via Bayesian filtering and models the measurements in the scene via CRF. In order to use CRFs in Bayesian filtering scenario, we solve two problems, namely, matching generative Bayesian filtering framework with discriminative CRFs, and tractable computation of the recursive updates over the exponential output space of CRFs. We present an approximation using Jensen inequality to convert the discriminative likelihood of the CRF into generative measurement equation. For tractable computation, we first show that the posterior belief in an rCRF framework is equivalent to a CRF with an energy function including both the scene model and the Bayesian updates. This equivalence enables us to use structured diversity methods developed for CRFs. Since we define the belief function recursively, we iterate the message propagation and diverse sampling until the convergence. To the best of our knowledge, rCRF is the only tractable method that can use a CRF model in a Bayesian filtering.



We apply the rCRF to the problem of human activity detection and anticipation. In order to do so, we apply rCRF model to the recently proposed CRF-based human activity detection. Following, we represent the scene as a CRF over human and object nodes. We then use the observations from RGB-D videos to detect activities via rCRF. We also use the same CRF within rCRF framework in order to anticipate the future activities.

We experimentally evaluate our method on the CAD-120 human activity dataset. Our experiments show that we outperform the state-of-the-art methods in the detection and the anticipation, and the improvement in the anticipation accuracy is quite significant. In addition to the improvements over accuracy, we show that our anticipation inference also improves the computation time and runs near real-time.

In summary, the contributions of this work are:

_item
We present Recursive-CRF (rCRF) that uses the rich modeling power of CRF in
Bayesian filtering setting.


We present a computationally-tractable inference algorithm using structured diversity and  Jensen inequality.
We apply our rCRF approach to the problem of activity detection and anticipation in
RGB-D videos.
Our experiments show that rCRF significantly outperforms the state-of-the-art methods, both in accuracy and inference time.




Background and Related Work


Bayesian Recursive Filtering:
Estimating a belief over variables of interest (state) from partial observations is a widely studied problem. Sequential Monte Carlo (SMC) -also known as particle filter- is typically used to estimate beliefs in high-dimensional cases. SMC methods represent the belief as set of samples and we refer the reader to for rigorous analysis of SMC methods.

SMC methods are not directly applicable to spaces like CRF since the number of samples required is intractably high. One solution to this problem is the Rao-Blackwellised particle filter. It uses a partition of the state variables  into two set of variables  and  such that the variables in one partition  can be estimated using the partition . Then Rao-Blackwellised particle filter estimates the  via SMC and estimates the  by using . However, for our problem, we are not aware of any state decomposition which enables Rao-Blackwellised particle filter.

One tractable application of the SMC framework to the CRF based scene analysis problems is the ATCRF model. ATCRF uses a set of heuristics to sample the particles. However, ATCRF also faces the problem of computational limitations and requires computationally intractable number of samples for long range anticipation. We directly follow the Bayesian filtering theory and efficiently estimate the belief by proposing rCRF.


Structured Diversity and Variants of CRFs:
CRFs are widely used to solve many activity analysis problems in a discriminative setting. CRF models the conditional likelihood of the state given the partial observations, and the MAP solution can be efficiently found. Although this deterministic setting is quite powerful, it does not give any information about the belief other than the MAP state.

In addition to the MAP solution, it is also tractable to compute the modes of the CRF. Moreover, these modes can be considered as an approximate state space, and the belief can be computed only for these samples. Indeed, this claim is empirically validated in many problems such as parameter learning, empirical MBR and generating a set of plausible segmentations.

Among the aforementioned structured diversity approaches, human pose estimation from videos via diverse-m-best solutions is a method applicable to the sequential information. starts by dividing the video into a set of frames and computes the diverse-most-likely solutions of each frame independently without any temporal cue. Then, it combines the results via the Viterbi algorithm utilizing the temporal relations. Since the sampling procedure does not use any temporal information, resultant samples are typically not accurate. On the contrary, we formulate the problem as Bayesian filtering and compute the samples based on temporal relations. Formally, given state variables  and observations , we directly sample , whereas, samples . Since our sampling procedure uses the entire video instead of a single frame, our samples are more accurate.

There are variants of CRFs that rely on sequential models as well such as, Dynamic CRF (dCRF), Infinite Hidden CRF, Gaussian Process Latent CRF and Hierarchical Semi-Markov CRF (HSCRF). dCRF is proposed to share the parameters of the CRF among sequential data with an efficient MAP inference. Infinte hidden CRF and Gaussian Process Latent CRF models the temporal evolution through set of lineraly connected latent nodes. HSCRF is a recursive method for efficient inference and learning over hierarchical Markov decision processes. Although they are applicable to the videos, we are not aware of any tractable method to compute a belief over any of the aforementioned graphical model.

CRF-Filter is a closely related approach which uses CRFs in a particle filtering scenario. However, it is based on low dimensional state space (2D and 3D spaces) and it is not applicable to our rich model.


Human Activity Detection and Anticipation: Early works rely solely on human poses. These works range from jointly segmenting and recognizing sub-activities to choosing a relevant model out of activity models. Main limitation of these methods is that they do not use the object information. Some methods successfully model and use the relations of the human-poses and objects in the scene. However, a significant drawback of these works is missing the fact that object affordance is more important than object types for activities. Indeed, object affordance based models had higher performance (e.g.,).

Another drawback of these methods is the requirement of the entire activity. Detecting the activity in its early stages is especially crucial for assistive robotics and surveillance systems. Although a few recent work solves the problem of activity detection with partial/early information, these works do not perform anticipation. There are a few recent works in what will a human perform next by using trajectory prediction. It is possible to predict the trajectory of the human  using inverse reinforcement learning in 2D or 3D. However, these models rely on the low-dimensional structure of the 2D/3D coordinate space and therefore they do not apply to rich models like CRF.

Recent work on anticipatory temporal CRF considers an anticipation with a CRF model. It anticipates the future via augmenting set of possible future observations to the CRF. However, its accuracy significantly drops for a long horizon. More importantly it fails to represent the uncertainty since it only finds the MAP solution although the future is expected to have many possibilities with different probabilities. Our method overcomes these problems by recursively estimating a full belief.





Overview


    
  A sampling approach to recursively represent the belief over an rCRF. Each iteration of the recursive estimation algorithm includes computing forward and backward messages  by using current samples and computing belief  with the propagated messages. Then, we re-compute the messages and re-sample the belief until the belief converges. Here,  and  
  
  
Here we present the high-level algorithm by using human activity detection and anticipation application. We explain the rCRF using an example scene consisting of two objects (a microwave and a bowl) and a human in Figure .


Reasoning about an high-level concept like an activity requires not only identifying the objects but also interpreting object-object relations and human-object relations. Indeed, rCRF captures such a rich information via CRF. As shown in the Figure , each object and a human corresponds to a node in the graph on which we define the CRF. As a hidden variable, we are interested in object affordances like openable, graspable, movable, etc., and the activity human is performing moving, opening, grasping, etc.. We denote the affordance variables at time  as  and , and the activity variable as . Since these variables are not directly visible, we estimate them by using a set of observations. We are using the 3D positions of the objects  and the human pose  as observations. Human pose corresponds to the 3D position of the joints of the human in the scene.

In addition to the spatial relations of objects and humans, we are also interested in their temporal evolution. In general, this problem corresponds to a Bayesian smoothing problem. We are interested in hidden states , and we are given set of observations  to estimate it.

rCRF efficiently solves the Bayesian smoothing problem through a method that we develop in Section . As shown in Figure , we first compute the forward and backward messages  by using the current samples at each iteration of the rCRF. We then compute the posterior belief  by using messages and the CRF-likelihood . As a final step of the iteration, we represent the belief via diverse samples of the posterior belief. Since the belief is recursively defined, we re-compute the messages and re-sample the belief until it converges.




Belief Estimation with  rCRF
In this section, we develop the Recursive Conditional Random Field (rCRF) to use CRF in a Bayesian filtering setting. rCRF jointly uses rich model of CRF and recursive nature of the Bayesian filtering to compute an accurate belief. We first define the rCRF in Section , and then we introduce a link between CRF likelihood and measurement likelihood in Section  in order to compute posterior belief. In Section , we further show that the resulting posterior belief is equivalent to a CRF. Moreover, this equivalence enables efficient computation via the diversity based method developed for CRFs.
Recursive Conditional Random Field

Consider a sequential estimation problem in which we are interested in variables  using observations  where  is the temporal variable. In our application scenario,  is the frame number,  is the RGB-D camera reading, and the  is the object and activity labels. We now define the Recursive Conditional Random Field (rCRF) for such problem.


Let  be set of graphs indexed by the temporal variable  and  is indexed by the vertices of  as . Then, (,) is a Recursive Conditional Random Field with dynamics  when

_enum
	For each ,  is a CRF over 

 (Markov)


 
 (stationarity)





rCRF as a graphical model. rCRF is a hybrid random field since it combines directed and undirected edges.


We now state the main purpose of our work. We are interested in the belief over state variables at given time instant  as:

Here,  denotes the length of the video. Hence, in rCRF the belief of any frame is supported by the entire video.


We then decompose the belief by using the independence properties of the rCRF as:

Moreover,  and  can be computed recursively by using forward and backward  messages. Following,

with initializations  and .

Computing the belief using an rCRF

Recursive definition in () has two significant drawbacks:
 firstly, CRF is modelling  instead of  and the transformation is not trivial. Secondly, computation of the messages require a summation over the entire output space, and it has an exponential dimension. In this section, we first compute the posterior of the observation given labels  by using the CRF posterior likelihood . Then, we show that the belief function at time , , can be approximately represented as a Gibbs measure over . Then, we conclude that belief is a CRF over the graph  with modified energy functions. 
From  to 
Since  is a CRF, the posterior of the label given the observation follows a Gibbs measure as;

where  is the energy function defined over the node set  as  and over the edge set  as .

In order to transform   into  , we use Bayes rule;
 and compute the denominator as;

For tractability, we approximate the  with its lower bound after applying the Jensen inequality as;



We then estimate the inner summations 


from the training data

using Monte Carlo method

 as  where  is the number of training samples and  is the  sample.
 
 Therefore, we can compute the observation likelihood as:  


Belief is a CRF
Here we compute the belief () in terms of forward and backward messages and CRF likelihood. We then show that the posterior belief is a CRF. This observation enables us to use efficient methods developed for CRFs.

In order to compute the belief (), we decompose


the system dynamics using the independency assumption in the graph in Fig. .
This gives us .





We then compute the belief function as  by using equations () and (). After algebraic manipulations, the belief function can be approximated as follows (see supplementary material for a detailed derivation):


where 

One important property to observe is the decomposition of the belief over the graph in (). () is a summation over energy terms defined over nodes  and edges . Hence, belief  is a Gibbs measure over . By using Hammersley-Clifford theorem, we  conclude that the posterior belief in rCRF is a CRF. In other words, belief is a CRF defined over the same graph with a modified energy function.


Belief via Diverse-Most-Likely Samples

Since we computed the belief function and showed it is equivalent to a CRF, we now need
an efficient method for efficiently computing the belief.



We follow the observation that CRF-likelihood over a natural scene concentrates on a few diverse samples because each scene only has a few plausible explanation. Hence, we try to compute the belief for only those samples. In other words, let's assume the set of samples at time  is . We redefine the belief as;



Since there are only a few plausible explanation of a visual observation and CRF-based belief concentrates only on those samples, proper selection of the samples  is expected to work well in practice. These samples are typically selected as the diverse-most-likely solutions of the CRF. They are most-likely samples because we are only interested in the plausible explanations. Moreover, they are diverse because we are interested in the modes of the CRF other than set of samples around the MAP solution. Diversity is achieved via the requiring samples to be at least  unit apart from each other according to a distance function . Moreover, we use hamming distance as a distance function in our experiments. In other words, we solve the following optimization problem;

where  is the  sample in the  frame. Moreover, this optimization is NP-hard in general; however, since we already showed  is CRF, we use the existing diverse mode finding algorithms developed for CRFs. We use Lagrange relaxation by Batra et.al. We explain the details of solving this optimization problem by using in supplementary materials.

In summary, we first compute the belief via () for all frames by using samples of the previous and the next frame as well as CRF likelihoods. Then, we compute the diverse samples of () by using. After computing the samples, we compute the messages  and  by using the equations () and (). We continue to re-sample the beliefs and re-compute the messages recursively until the convergence. Moreover, during the initialization, we only sample the observation function () since the messages are not available.



Human Activity Detection and Anticipation
In this section, we describe how we apply the rCRF model to RGB-D videos for human activity detection and anticipation. We are interested in activities like reaching and moving, and object affordances like reachable and movable as explained in Section .

We follow the approach in, and start with temporally segmenting the video. This step can be considered as an oversegmentation in the temporal domain. It decreases the computation complexity and enables using motion information as an observation. We then obtain the observation vectors , by detecting the objects in the first frame and then tracking their locations. We also obtain the human pose  through a skeleton tracker.

We consider affordances and activities as state  where  is the number of objects.  We learn the energy function defined in () by using the Structural SVM as in the case of. We use the first order statistics for temporal dynamics as  where  is the number of the co-occurrence of the label pairs in training data.

After defining the observation, state and dynamics, we apply the rCRF model. We also summarize the activity detection and anticipation application in Algorithm .

Compute belief the over  for  in an RGB-D Video of length 

Initialization:
Compute , and  for  via.
Compute  for  via ()
Compute the belief via () w/o messages ()

Detection:


Compute the forward/backward messages via ()
Compute the belief via () an sample via ()

convergence or number of iterations limit
Anticipation:

Compute only the forward messages via ()
Sample the belief directly from the forward messages.




Moreover, since the temporal relations are modeled as causal, we do not compute the backward messages during the anticipation. In anticipation setting, there is also no observation. Hence, the belief is defined solely by the forward messages. In order to compute the belief for future frames, we propagate the estimated belief iteratively. We propagate the belief to the next frame by sampling the next state of the each sample in the belief of the current frame via the temporal dynamics. Then, we choose diverse most likely samples over the propagated samples via exhaustive search.



Experimental Results
In order to experimentally evaluate the proposed rCRF model and the belief computation, we perform experiments on two different applications. Firstly, we estimate a belief over the activity human performing and the affordances of the objects in the scene by using the RGB-D video. After computing the belief, we detect the most likely activity and affordance sequences over the belief. Then, we study the improvement in the detection accuracy caused by the proposed method. Secondly, we test the accuracy of the beliefs in the anticipation setting. Indeed, we show that it is possible to obtain high-quality anticipation via rCRF.

*[ht]


&



&


Anticipated belief over activity. In the first and third row, we show a middle frame of the temporal segment. In the second and fourth row, we show the anticipated belief. Note that frames are not visible to the algorithm and only included for evaluation.



Data: We use CAD-120 dataset in order to evaluate our method. CAD-120 dataset includes 120 RGB-D videos of four different subject performing activities reaching, moving, pouring, etc. while interacting with objects having affordances reachable, movable, pourable, etc..

Experimental Setup: For computing the features and learning the CRF parameters, we follow the approach and the code in. Following the convention in, we use 4-fold cross-validation by training over the data from 3 subjects and testing on the remaining subject. We then average the results over 4-folds. We implemented the rCRF as we explain in Algorithm  with the following parameters; we sampled  diverse samples and ran the recursive message updates with the number of iterations limit as .

For the anticipation setting, we define the  seconds into the future experiment as an experiment over all feasible  seconds anticipation scenarios. In other words, we anticipated the segment  by using the segments  for all  where  is the length of the video. Then, we averaged the score over all feasible experiments .

Baseline Algorithms: In detection setting, we compare the detection results of the rCRF based belief estimation method to MAP solution of the spatiotemporal CRF in. Moreover, in the anticipation setting, we compare the rCRF with the state-of-the-art anticipation method. In order to evaluate the improvements caused by the recursive modeling and the structured diversity separately, we also compare the rCRF with a recursive approach without diversity and a diversity-based approach without recursive modeling baselines in both detection and anticipation.

The DivMBest algorithm in uses the diverse sampling method to sample CRFs defined over each frame separately. DivMBest then finds the most likely sequence via Viterbi algorithm. Since it is missing the recursive modeling, it serves as structured diversity without recursive filtering baseline. We replace the diversity-based sampling in our method with Gibbs sampler and consider it as recursive filtering approach without structured diversity baseline. For the Gibbs sampling, we sampled  samples per temporal segment. We denote the recursive approach with Gibbs sampling as "rCRF w/o div" while tabulating the results. For a fair comparison, we used the same temporal dynamics for proposed method and baselines. We also include the chance.

Evaluation Metrics: For activity detection, we compute the ratio of the correctly classified labels (micro precision) and the averages of the precision and recall values computed for each activity and object affordance classes (macro precision and macro recall). For anticipation, we record the ratio of the correctly classified labels micro precision, the average of the f-1 score that is computed for each activity and object affordance class (macro f-1 score), and the precision of the top 3 anticipated labels (robot anticipation metric). While computing the robot anticipation metric; if any of the top 3 anticipation is correct, it is counted as true positive.

We discuss the results in light of the following sections:

Accuracy of the rCRF in detection setting.
We evaluate the rCRF for activity detection and summarize the results in Table . Table  suggests that the rCRF outperforms the MAP solution. Since rCRF and are using the same spatial relations, the performance difference is due to the modeling of the temporal relations in rCRF. We use first-order statistics as temporal dynamics, and they are quite accurate as shown in the heatmap in Figure . They also capture semantic information like objects become stationary after being used.


    [Human Activity]
    

 

  
   
[Object Affordance] 
     

 

 


  Heatmap of the first-order statistics of activity and object affordance classes. They are used as temporal dynamics by rCRF.
  

Accuracy of the rCRF in anticipation setting.
We evaluate the accuracy of the belief we compute via rCRF, both quantitatively and qualitatively. For qualitative evaluation, we show the segment that we are anticipating the belief over, as well as the belief we obtain in Figure . Please note that, this visual information is not visible to the algorithm, and it is only included for the subjective evaluation.

As shown in the figure, anticipated belief is capturing the scene accurately. Belief is accurate even for the case of concurrent activities. For example, in the second column of the second row in Figure , subject is reaching the microwave and moving the cleaner. Our method assigns similar likelihood values to both reaching and moving.

We also perform quantitative analysis over anticipation accuracy. We anticipated 3 seconds into the future and summarized the results in Table . As shown in the Table , rCRF outperforms the state-of-the-art heuristic method significantly as well as all other baselines. We believe this result is due to the accurate joint-modeling of the temporal relations and the CRF model. We further analyzed this behavior in the subsequent sections.



Detection Performance over CAD-120.  We compare rCRF with MAP solution and baselines for detections accuracy.






Anticipation performance for the anticipating 3 seconds in the future. We compare rCRF with state-of-the-art anticipation algorithm and baselines for anticipation accuracy.




How important is the recursive modeling?
DivMBest is the application of the structured diversity without recursive modeling of the Bayesian filtering. In all experiments (Table  and ), rCRF outperforms the DivMBest. We believe this is because rCRF samples   instead of  as in the case of. In other words, DivMBest samples without considering temporal relations and use temporal information while computing the ML solution; on the contrary, we sample the full belief directly.

During our experiments, we also observed that the convergence always occurred after a few iterations. Hence, a single temporal segment does not carry enough information and accurate handling of the temporal relations is necessary for an accurate belief estimation.


r0.3


Entropy of the belief vs. time (uniform dist. has  bit entropy)


In order to further evaluate the importance of the recursive modeling, we experimented the effect of anticipation horizon. We computed the average micro-precision of our method and competing ones for anticipation horizons between 1 and 10 seconds and plotted in Figure . We only include the result on object affordance anticipation and rest of the results are included in the supplementary material. In Figure , accuracy of all algorithms decreases with increasing horizon. One interesting observation is decrease rate of DivMBest is steeper than others. Since DivMBest misses the recursive nature of the problem, accuracy of the belief it computes is limited; hence, the resulting belief does not stay informative with increasing horizon. We further computed the entropy of the belief rCRF computes and plotted its average in Figure . The decrease rate of the accuracy is much smaller than the increase rate of the entropy. In summary, recursive modeling is necessary for an accurate belief estimation and rCRF computes flatter yet still informative beliefs with increasing horizon.


How to efficiently cover the output space?
In order to see the effect of structural diversity on covering the output space, we compare the rCRF with a version of it in which we replace diverse sampling with the Gibbs sampler. As expected, Gibbs sampler only sampled the small region around the posterior and failed to cover the output space. Within all experiments, rCRF outperforms Gibbs sampler baseline. On the other hand, as shown in Figure , rCRF with Gibbs sampler outperforms the DivMBest method. Hence, we conclude that although the resulting belief misses some part of the output space, it still stays informative for a longer horizon because of the recursive modeling. Moreover, uses the domain knowledge by selectively sampling points around the hand, etc. and it performs better than both baselines. We believe this result is due to the efficient coverage of the output space with heuristics.


    Precision vs. anticipation horizon for object affordance.


Computationally-efficient inference:
We also evaluated the computational efficiency of the rCRF. We computed the average computation time for anticipating 3 second in the future by using rCRF and the ATCRF. Within our experiments, we did not include any pre-processing or feature extraction computation (they are same for all algorithms). Our experiments suggest that the rCRF is faster than the heuristic-based method as shown in Table . Hence, rCRF model outperforms the state-of-the-art anticipation algorithm in terms of speed in addition to the accuracy.
[h!]
    
Computation time for anticipating 3 seconds in the future excluding pre-processing (see supplementary material for details).

  
  
  


Conclusions
In this work, we consider the problem of using rich CRF-based scene models in Bayesian filtering setting. We presented the rCRF model which uses rich modeling power of CRFs in recursive Bayesian filtering. We further developed a computationally-tractable method based on Jensen inequality and structured diversity. We extensively experimented the proposed method against the state-of-the-art methods and various baselines. We showed that the rCRF can accurately anticipate the future beliefs over CRFs. We also experimentally demonstrated that the recursive framework is necessary for accurate anticipation. Moreover, rCRF not only enables more accurate anticipation but also improves the computation time.

plainnat


